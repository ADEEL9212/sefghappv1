"""
from now on any agent is just a function and same goes the workers

packages:
1. agents
2. workers
3. tempDB
4. processTrackerDB
5. apiKeys
"""
import json
import math
import time

from workers import repoSignalModes, RepoFetcher, sel4wor
from processTrackerDB import processLogger as Logger
from processTrackerDB import loggerDB
from tempDB import repoTempDB
from tempDB import similarityReportDB
from agents import promptAnalyzer, DynamicSearchOptimizer, Query2RepoTransformer, SimilarityAnalyser
from workers import promptSplitter, RepoFeeder

rtDB = repoTempDB()
srDB = similarityReportDB()


def Info():
   print(output := "\n".join([
      "Engine Model: CHAMP 50CC",
      "Engine Version: ",
      "Project Title: Search Engine For Github (SEFGH) - AI",
      "-" * 40
   ]))
   return output


def coreEngine(userQuery:str,searchType:str):

   repoFetchMode = "fast" #default mode

   if searchType == "quick":
      repoFetchMode = "fast"
   elif searchType == "exhaustive":
      repoFetchMode="exhaustive"

   searchQuery = f"""{userQuery}""" #converting to doc string as it preserves user input and not interpret by python
   Logger(name="User Prompt",value=[searchQuery],fromProcess=["null"], toProcess=["promptAnalyzer"])

   AnalyzerReport = promptAnalyzer(str(searchQuery))
   Logger(name="promptAnalyzer",value=[AnalyzerReport],fromProcess=["User Prompt"], toProcess=["promptSplitter"])

   dynamicSearchInput, queryTransformerInput, AnalysisReport = promptSplitter(AnalyzerReport) #internally uses the extract json
   Logger(name="promptSplitter", value=[f"dynamicSearchInput: {dynamicSearchInput}",f"queryTransformerInput: {queryTransformerInput}",f"AnalysisReport: {AnalysisReport}"], fromProcess=["AnalyzerReport"] ,toProcess=["DynamicSearchOptimizer","Query2RepoTransformer"])

   SearchOptimizerReport = DynamicSearchOptimizer(dynamicSearchInput, level="basic")
   Logger(name="DynamicSearchOptimizer",value=[SearchOptimizerReport],fromProcess=["promptSplitter"],toProcess=["RepoFetcher"])

   print("sending to repo fetcher this", json.dumps(json.loads(SearchOptimizerReport)["query"]))

   gitQuery = str( json.dumps(json.loads(SearchOptimizerReport)["query"]))

   TransformerReport = Query2RepoTransformer(queryTransformerInput)
   Logger(name="Query2RepoTransformer", value=[TransformerReport],fromProcess=["promptSplitter"], toProcess=["SimilarityAnalyser"])

   noOfResultsIsZero = 0  # this is used to get a repo in case previous query not fetch a repo

   while noOfResultsIsZero == 0:  # this loops runs until an 1 or more repos are found
      SearchOptimizerReport = str(
         sel4wor(gitQuery))  # selects 4 words randomly from the query generated by DynamicSearchQueryAgent
      print('\nwords selected: ', SearchOptimizerReport, "\n")
      NoOfResultsFound, first3, RepoStopSignal = RepoFetcher(SearchOptimizerReport, rtDB,
                                                             "fast")  # all results saved in database
      Logger(name="RepoFetcher", value=[NoOfResultsFound, first3], fromProcess=["DynamicSearchOptimizer"],
             toProcess=["RepoFeeder"])
      noOfResultsIsZero = NoOfResultsFound  # updating

   time.sleep(10)  # wait for token limit to dissolve

   print("\nRepo Temp DB: \n")
   rtDB.printDB()

   Logger(name="RepoCycleStart", value=["RepoCycleStart"], fromProcess=["RepoCycleStart"], toProcess=["RepoCycleStart"])
   print("\nRepoStopSignal state:", RepoStopSignal)
   count = 0  # this is used for limiting the rate limits of groq api
   while RepoStopSignal == repoSignalModes[1]:
      SimilarityReport = SimilarityAnalyser(RepoFeeder(rtDB), TransformerReport)
      print("\n\n", SimilarityReport)

      if SimilarityReport == "noMoreReports":
         RepoStopSignal = repoSignalModes[0]  # this will break the loop
      else:
         rowNumber = srDB.appendReport(SimilarityReport)
         Logger(name="SimilarityAnalyser", value=[srDB.getRow(rowNumber)],
                fromProcess=["RepoFeeder", "Query2RepoTransformer"], toProcess=["similarityDB"])
         time.sleep(5 + (20 - 5) * (1 + math.cos((2 * math.pi * count) / 5)) / 2)  # to avoid token limit per minute
         count += 1

   Logger(name="RepoCycleEnd", value=["RepoCycleEnd"], fromProcess=["RepoCycleEnd"], toProcess=["RepoCycleEnd"])


def run(searchDesc):
   coreEngine(searchDesc,"fast") #sending description to the inference engine

   print("\nLogger DB: \n")
   loggerDB.printDB()
   loggerDB.saveDB("logger", "md")

   print("\nRepo Temp DB: \n")
   rtDB.printDB()

   print("\nSimilarity DB: \n")
   srDB.printDB()
   srDB.saveDB("similarity", "md")

   return srDB.returnDF().to_dict(orient="records")
